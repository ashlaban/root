// @(#)root/tmva $Id$
// Author: Kim Albertsson

/*************************************************************************
 * Copyright (C) 2017, Kim Albertsson                                    *
 * All rights reserved.                                                  *
 *                                                                       *
 * For the licensing terms see $ROOTSYS/LICENSE.                         *
 * For the list of contributors see $ROOTSYS/README/CREDITS.             *
 *************************************************************************/

//////////////////////////////////////////////////////////////////////////////
///
//////////////////////////////////////////////////////////////////////////////
#include "TMVA/CrossEvaluation.h"

#include "TMVA/ClassifierFactory.h"
#include "TMVA/Config.h"
#include "TMVA/CvSplit.h"
#include "TMVA/DataSet.h"
#include "TMVA/Event.h"
#include "TMVA/MethodBase.h"
#include "TMVA/MethodCrossEvaluation.h"
#include "TMVA/MsgLogger.h"
#include "TMVA/ResultsClassification.h"
#include "TMVA/ResultsMulticlass.h"
#include "TMVA/ROCCurve.h"
#include "TMVA/tmvaglob.h"
#include "TMVA/Types.h"

#include "TSystem.h"
#include "TAxis.h"
#include "TCanvas.h"
#include "TGraph.h"
#include "TMath.h"

#include <iostream>
#include <memory>

/**
* \class TMVA::CrossEvaluation
* \ingroup TMVA
* \brief

Use html for explicit line breaking<br>
Markdown links? [class reference](#reference)?


~~~{.cpp}
ce->BookMethod(dataloader, options);
ce->Evaluate();
~~~

Cross-evaluation will generate a new training and a test set dynamically from
from `K` folds. These `K` folds are generated by splitting the input training
set. The input test set is currently ignored.

This means that when you specify your DataSet you should include all events
in your training set. One way of doing this would be the following:

~~~{.cpp}
dataloader->AddTree( signalTree, "cls1" );
dataloader->AddTree( background, "cls2" );
dataloader->PrepareTrainingAndTestTree( "", "", "nTest_cls1=1:nTest_cls2=1" );
~~~

## Split Expression
See CVSplit documentation?

*/

////////////////////////////////////////////////////////////////////////////////
///    

TMVA::CrossEvaluation::CrossEvaluation(TString jobName, TMVA::DataLoader *dataloader, TFile * outputFile, TString options)
   : TMVA::Envelope(jobName, dataloader, nullptr, options),
     fAnalysisType(Types::kMaxAnalysisType),
     fAnalysisTypeStr("auto"),
     fCorrelations(kFALSE),
     fCvFactoryOptions(""),
     fFoldFileOutput(kFALSE),
     fFoldStatus(kFALSE),
     fJobName(jobName),
     fNumFolds(2),
     fOutputFactoryOptions(""),
     fOutputFile(outputFile),
     fSilent(kFALSE),
     fSplitExprString(""),
     fROC(kTRUE),
     fTransformations(""),
     fVerbose(kFALSE),
     fVerboseLevel(kINFO)
{
   InitOptions();
   ParseOptions();
   CheckForUnusedOptions();

   if (fAnalysisType != Types::kClassification and fAnalysisType != Types::kMulticlass) {
      Log() << kFATAL << "Only binary and multiclass classification supported so far." << Endl;
   }
}

////////////////////////////////////////////////////////////////////////////////
///

TMVA::CrossEvaluation::CrossEvaluation(TString jobName, TMVA::DataLoader *dataloader, TString options)
   : CrossEvaluation(jobName, dataloader, nullptr, options)
{}

////////////////////////////////////////////////////////////////////////////////
///

TMVA::CrossEvaluation::~CrossEvaluation()
{}

////////////////////////////////////////////////////////////////////////////////
///

void TMVA::CrossEvaluation::InitOptions()
{
   // Forwarding of Factory options
   DeclareOptionRef( fSilent,   "Silent", "Batch mode: boolean silent flag inhibiting any output from TMVA after the creation of the factory class object (default: False)" );
   DeclareOptionRef( fVerbose, "V", "Verbose flag" );
   DeclareOptionRef( fVerboseLevel=TString("Info"), "VerboseLevel", "VerboseLevel (Debug/Verbose/Info)" );
   AddPreDefVal(TString("Debug"));
   AddPreDefVal(TString("Verbose"));
   AddPreDefVal(TString("Info"));
   
   DeclareOptionRef( fTransformations, "Transformations", "List of transformations to test; formatting example: \"Transformations=I;D;P;U;G,D\", for identity, decorrelation, PCA, Uniform and Gaussianisation followed by decorrelation transformations" );

   DeclareOptionRef(fCorrelations, "Correlations", "Boolean to show correlation in output");
   DeclareOptionRef(fROC, "ROC", "Boolean to show ROC in output");

   TString analysisType("Auto");
   DeclareOptionRef( fAnalysisTypeStr, "AnalysisType", "Set the analysis type (Classification, Regression, Multiclass, Auto) (default: Auto)" );
   AddPreDefVal(TString("Classification"));
   AddPreDefVal(TString("Regression"));
   AddPreDefVal(TString("Multiclass"));
   AddPreDefVal(TString("Auto"));

   // Options specific to CE
   DeclareOptionRef( fSplitExprString, "SplitExpr", "The expression used to assign events to folds" );
   DeclareOptionRef( fNumFolds, "NumFolds", "Number of folds to generate" );

   DeclareOptionRef( fFoldFileOutput, "FoldFileOutput", "If given a TMVA output file will be generated for each fold. Filename will be the same as specifed for the combined output with a _foldX suffix. (default: false)" );
}

////////////////////////////////////////////////////////////////////////////////
///

void TMVA::CrossEvaluation::ParseOptions()
{
   this->Envelope::ParseOptions();

   // Factory options
   fAnalysisTypeStr.ToLower();
   if     ( fAnalysisTypeStr == "classification" ) fAnalysisType = Types::kClassification;
   else if( fAnalysisTypeStr == "regression" )     fAnalysisType = Types::kRegression;
   else if( fAnalysisTypeStr == "multiclass" )     fAnalysisType = Types::kMulticlass;
   else if( fAnalysisTypeStr == "auto" )           fAnalysisType = Types::kNoAnalysisType;

   if (fVerbose) {
      fCvFactoryOptions += "V:";
      fOutputFactoryOptions += "V:";
   } else {
      fCvFactoryOptions += "!V:";
      fOutputFactoryOptions += "!V:";
   }

   fCvFactoryOptions += Form("VerboseLevel=%s:", fVerboseLevel.Data());
   fOutputFactoryOptions += Form("VerboseLevel=%s:", fVerboseLevel.Data());

   fCvFactoryOptions += Form("AnalysisType=%s:", fAnalysisTypeStr.Data());
   fOutputFactoryOptions += Form("AnalysisType=%s:", fAnalysisTypeStr.Data());

   if (fTransformations != "") {
      fCvFactoryOptions += Form("Transformations=%s:", fTransformations.Data());
      fOutputFactoryOptions += Form("Transformations=%s:", fTransformations.Data());
   }

   if (fCorrelations) {
      // fCvFactoryOptions += "Correlations:";
      fOutputFactoryOptions += "Correlations:";
   } else {
      // fCvFactoryOptions += "!Correlations:";
      fOutputFactoryOptions += "!Correlations:";
   }

   if (fROC) {
      // fCvFactoryOptions += "ROC:";
      fOutputFactoryOptions += "ROC:";
   } else {
      // fCvFactoryOptions += "!ROC:";
      fOutputFactoryOptions += "!ROC:";
   }

   if (fSilent) {
      // fCvFactoryOptions += Form("Silent:");
      fOutputFactoryOptions += Form("Silent:");
   }

   fCvFactoryOptions += "!Correlations:!ROC:!Color:!DrawProgressBar:Silent";

   // CE specific options
   if (fFoldFileOutput and fOutputFile == nullptr) {
      Log() << kFATAL << "No output file given, cannot generate per fold output." << Endl;
   }

   // Initialisations

   fFoldFactory = std::unique_ptr<TMVA::Factory>(
      new TMVA::Factory(fJobName, fCvFactoryOptions));

   // The fOutputFactory should always have !ModelPersitence set since we use a custom code path for this.
   //    In this case we create a special method (MethodCrossEvaluation) that can only be used by
   //    CrossEvaluation and the Reader.
   if (fOutputFile == nullptr) {
      fFactory = std::unique_ptr<TMVA::Factory>(new TMVA::Factory(fJobName,  fOutputFactoryOptions));
   } else {
      fFactory = std::unique_ptr<TMVA::Factory>(new TMVA::Factory(fJobName, fOutputFile,  fOutputFactoryOptions));
   }

   fSplit = std::unique_ptr<CvSplitCrossEvaluation>(new CvSplitCrossEvaluation(fNumFolds, fSplitExprString));
   
}

////////////////////////////////////////////////////////////////////////////////
///

void TMVA::CrossEvaluation::SetNumFolds(UInt_t i)
{
   if (i != fNumFolds) {
      fNumFolds = i;
      fSplit = std::unique_ptr<CvSplitCrossEvaluation>(new CvSplitCrossEvaluation(fNumFolds, fSplitExprString));
      fDataLoader->MakeKFoldDataSet(*fSplit.get());
      fFoldStatus=kTRUE;
   }
}

////////////////////////////////////////////////////////////////////////////////
///

void TMVA::CrossEvaluation::SetSplitExpr(TString splitExpr)
{
   if (splitExpr != fSplitExprString) {
      fSplitExprString = splitExpr;
      fSplit = std::unique_ptr<CvSplitCrossEvaluation>(new CvSplitCrossEvaluation(fNumFolds, fSplitExprString));
      fDataLoader->MakeKFoldDataSet(*fSplit.get());
      fFoldStatus=kTRUE;
   }
}

////////////////////////////////////////////////////////////////////////////////
/// Evaluates each fold in turn.
///   - Prepares train and test data sets
///   - Trains method
///   - Evalutes on test set
///   - Stores the evaluation internally
///
/// @param iFold fold to evaluate
///

void TMVA::CrossEvaluation::ProcessFold(UInt_t iFold)
{
   TString methodName    = fMethod.GetValue<TString>("MethodName");
   TString methodTitle   = fMethod.GetValue<TString>("MethodTitle");
   TString methodOptions = fMethod.GetValue<TString>("MethodOptions");

   Log() << kDEBUG << "Fold (" << methodTitle << "): " << iFold << Endl;

   // Get specific fold of dataset and setup method
   TString foldTitle = methodTitle;
   foldTitle += "_fold";
   foldTitle += iFold+1;

   // Only used if fFoldOutputFile == true
   TFile * foldOutputFile = nullptr;

   if (fFoldFileOutput and fOutputFile != nullptr) {
      TString path = std::string("") + gSystem->DirName(fOutputFile->GetName()) + "/" + foldTitle + ".root";
      std::cout << "PATH: " << path << std::endl;
      foldOutputFile = TFile::Open( path, "RECREATE" );
      fFoldFactory = std::unique_ptr<TMVA::Factory>(
         new TMVA::Factory(fJobName, foldOutputFile, fCvFactoryOptions)
      );
   }

   fDataLoader->PrepareFoldDataSet(*fSplit.get(), iFold, TMVA::Types::kTraining);
   MethodBase* smethod = fFoldFactory->BookMethod(fDataLoader.get(), methodName, foldTitle, methodOptions);

   // Train method (train method and eval train set)
   Event::SetIsTraining(kTRUE);
   smethod->TrainMethod();
   Event::SetIsTraining(kFALSE);

   if (fFoldFileOutput) {
      fFoldFactory->TestAllMethods();
      fFoldFactory->EvaluateAllMethods();
      foldOutputFile->Close();
   }

   // Clean-up for this fold
   {
      smethod->Data()->DeleteResults(foldTitle, Types::kTraining, smethod->GetAnalysisType());   
   }
   if (fFoldFileOutput) {
      smethod->Data()->DeleteResults(foldTitle, Types::kTesting, smethod->GetAnalysisType());
   }
   fFoldFactory->DeleteAllMethods();
   fFoldFactory->fMethodsMap.clear();
}

////////////////////////////////////////////////////////////////////////////////
/// Does training, test set evaluation and performance evaluation of using
/// cross-evalution.
///

void TMVA::CrossEvaluation::Evaluate()
{
   TString methodTypeName  = fMethod.GetValue<TString>("MethodName");
   TString methodTitle     = fMethod.GetValue<TString>("MethodTitle");
   if(methodTypeName == "") Log() << kFATAL << "No method booked for cross-validation" << Endl;

   TMVA::MsgLogger::EnableOutput();
   Log() << kINFO << "Evaluate method: " << methodTitle << Endl;

   // Generate K folds on given dataset
   if(!fFoldStatus){
       fDataLoader->MakeKFoldDataSet(*fSplit.get());
       fFoldStatus=kTRUE;
   }

   // Process K folds
   for(UInt_t iFold = 0; iFold < fNumFolds; ++iFold) {
      ProcessFold(iFold);
   }

   // Serialise the cross evaluated method

   TString options = Form("SplitExpr=%s:NumFolds=%i"
                          ":EncapsulatedMethodName=%s"
                          ":EncapsulatedMethodTypeName=%s",
                          fSplitExprString.Data(),
                          fNumFolds,
                          methodTitle.Data(),
                          methodTypeName.Data());
   fFactory->BookMethod(fDataLoader.get(), Types::kCrossEvaluation, methodTitle, options);
   
   // Evaluation
   fDataLoader->RecombineKFoldDataSet( *fSplit.get() );

   fFactory->TrainAllMethods();
   fFactory->TestAllMethods();
   fFactory->EvaluateAllMethods();

   Log() << kINFO << "Evaluation done." << Endl;
}
